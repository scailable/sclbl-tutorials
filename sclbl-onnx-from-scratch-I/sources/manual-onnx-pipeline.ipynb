{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This notebook accompanies the Scailable tutorial [Creating ONNX pipelines from scratch](). Please see the tutorial for details.\n",
    "\n",
    "The aim of this notebook is to create an ONNX pipeline which, given a vector containing the yard-size, indoor-area, and number of rooms of a house (`(yard,area,rooms)`):\n",
    "\n",
    "* Predicts the price of the house (using a trained model presented in \"Block 0\" below),\n",
    "* Checks whether the predicted price is smaller than 400.000, and the yard-size is larger than 0, \n",
    "* Returns a Boolean indicating whether or not the house if of interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 0: Preliminaries\n",
    "The code block below provides our startingpoint by fitting a simple linear regression model mapping the standardized feature vector `(yard, area, rooms)` to predict the log of the observed outcome `(price)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Values retrieved from training --- \n",
      "For input statdardization / pre-processing we need:\n",
      " - The column means [238.08108108 124.13513514   4.71744472]\n",
      " - The column sds [556.90768344  55.94648126   1.8576531 ]\n",
      "For the prediction we need:\n",
      " - The estimated coefficients: [[ 0.03990859  0.36480886 -0.00673619]]\n",
      " - The intercept: [12.69092987]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "# Open the training data:\n",
    "data = np.loadtxt(open(\"houses.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "\n",
    "# Retreive feature vectors and outcomes:\n",
    "datX = data[:, [1,2,3]]  # Input features (yard, area, rooms)\n",
    "datY = data[:, [0]]  # Price\n",
    "\n",
    "# Standardize the inputs:\n",
    "barX = np.mean(datX, 0)  # Mean for each of the inputs\n",
    "sdX = np.std(datX, 0)  # Sd for each of the inputs\n",
    "datZ = (datX - barX) / sdX\n",
    "\n",
    "# Log transform the output\n",
    "logY = np.log(datY)\n",
    "\n",
    "# Fit a linear model\n",
    "lin_mod = lm.LinearRegression()\n",
    "lin_mod.fit(datZ, logY)\n",
    "\n",
    "# retrieve intercept and fitted coefficients:\n",
    "intercept = lin_mod.intercept_\n",
    "beta = lin_mod.coef_\n",
    "\n",
    "print(\"--- Values retrieved from training --- \")\n",
    "print(\"For input statdardization / pre-processing we need:\")\n",
    "print(\" - The column means {}\".format(barX))\n",
    "print(\" - The column sds {}\".format(sdX))\n",
    "\n",
    "print(\"For the prediction we need:\")\n",
    "print(\" - The estimated coefficients: {}\".format(beta))\n",
    "print(\" - The intercept: {}\".format(intercept))\n",
    "\n",
    "# store the training results in an object to make the code more readable later on:\n",
    "training_results = {\n",
    "    \"barX\" : barX.astype(np.float32),\n",
    "    \"sdX\" : sdX.astype(np.float32),\n",
    "    \"beta\" : beta.astype(np.float32),\n",
    "    \"intercept\" : intercept.astype(np.float32),\n",
    "}\n",
    "\n",
    "# And, also creating the constraints (for usage in block 3):\n",
    "constraints = {\n",
    "    \"maxprice\" : np.array([400000]),\n",
    "    \"minyard\" : np.array([1]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is not neccesary for our main aim, but illustrates how to construct a prediction and evaluate our decision rules given a single obeservation (i.e., the properties of a single house):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed price: 500000.0, predicted price: [422147.75]\n",
      "Interesting? [False]\n"
     ]
    }
   ],
   "source": [
    "# Get the data from a single house\n",
    "first_row_example = data[1,:]\n",
    "input_example = first_row_example[[1,2,3]]  # The features\n",
    "output_example = first_row_example[0]  # The observed price  \n",
    "\n",
    "# 1. Standardize input for input to the model:\n",
    "standardized_input_example = (input_example - training_results['barX'])/ training_results['sdX']\n",
    "\n",
    "# 2. Predict the *log* price (using a dot product and the intercept)\n",
    "predicted_log_price_example = training_results['intercept'] + np.dot(standardized_input_example, training_results['beta'].flatten())\n",
    "\n",
    "\n",
    "# Compute the actual prediction on the original scale\n",
    "predicted_price_example = np.exp(predicted_log_price_example)\n",
    "print(\"Observed price: {}, predicted price: {}\".format(output_example, predicted_price_example))\n",
    "\n",
    "# See if it is interesting according to our simple decision rules:\n",
    "interesting = input_example[1] > 0 and predicted_price_example < 400000\n",
    "print(\"Interesting? {}\".format(interesting))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 1: Constructing the pre-processing pipeline\n",
    "This block of code constructs the pre-processing pipeline for our scenario in ONNX. Refer to the [Creating ONNX pipelines from scratch]() tutorial for naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the neccesary imports for blocks 1-X\n",
    "from onnx import helper as h\n",
    "from onnx import TensorProto as tp\n",
    "from onnx import checker\n",
    "from onnx import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The required constants:\n",
    "c1 = h.make_node('Constant', inputs=[], outputs=['c1'], name=\"c1-node\", \n",
    "        value=h.make_tensor(name=\"c1v\", data_type=tp.FLOAT, \n",
    "        dims=training_results['barX'].shape, \n",
    "        vals=training_results['barX'].flatten()))\n",
    "\n",
    "c2 = h.make_node('Constant', inputs=[], outputs=['c2'], name=\"c2-node\", \n",
    "        value=h.make_tensor(name=\"c2v\", data_type=tp.FLOAT, \n",
    "        dims=training_results['sdX'].shape, \n",
    "        vals=training_results['sdX'].flatten()))\n",
    "\n",
    "# The functional nodes:\n",
    "n1 = h.make_node('Sub', inputs=['x', 'c1'], outputs=['xmin'], name='n1')\n",
    "n2 = h.make_node('Div', inputs=['xmin', 'c2'], outputs=['zx'], name=\"n2\")\n",
    "\n",
    "# Create the graph\n",
    "g1 = h.make_graph([c1, n1, c2, n2], 'preprocessing',\n",
    "        [h.make_tensor_value_info('x', tp.FLOAT, [3])],\n",
    "        [h.make_tensor_value_info('zx', tp.FLOAT, [3])])\n",
    "\n",
    "# Create the model and check\n",
    "m1 = helper.make_model(g1, producer_name='scailable-demo')\n",
    "checker.check_model(m1)\n",
    "\n",
    "# Save the model\n",
    "save(m1, 'pre-processing.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check:\n",
      "The standardized input using onnx pipeline is: [array([-0.04503635,  0.76617634,  2.3053577 ], dtype=float32)]\n",
      " - Compare to standardized first row in block 0: [-0.04503634  0.76617624  2.30535792]\n"
     ]
    }
   ],
   "source": [
    "# A few lines to evaluate the stored model, useful for debugging:\n",
    "import onnxruntime as rt\n",
    "\n",
    "# test\n",
    "sess = rt.InferenceSession(\"pre-processing.onnx\")  # Start the inference session and open the model\n",
    "xin = input_example.astype(np.float32)  # Use the input_example from block 0 as input\n",
    "zx = sess.run([\"zx\"], {\"x\": xin})  # Compute the standardized output\n",
    "\n",
    "print(\"Check:\")\n",
    "print(\"The standardized input using onnx pipeline is: {}\".format(zx))\n",
    "print(\" - Compare to standardized first row in block 0: {}\".format(datZ[1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 2: Constructing the inference model\n",
    "The code block below constructs the ONNX inference task which, from the standardized input `zx` predicts the price on a log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The constants:\n",
    "c3 = h.make_node('Constant', inputs=[], outputs=['c3'], name=\"c3-node\", \n",
    "        value=h.make_tensor(name=\"c3v\", data_type=tp.FLOAT, \n",
    "        dims=training_results['beta'].shape, \n",
    "        vals=training_results['beta'].flatten()))\n",
    "\n",
    "c4 = h.make_node('Constant', inputs=[], outputs=['c4'], name=\"c4-node\", \n",
    "        value=h.make_tensor(name=\"c4v\", data_type=tp.FLOAT, \n",
    "        dims=training_results['intercept'].shape, \n",
    "        vals=training_results['intercept'].flatten()))\n",
    "\n",
    "# The operating nodes, Multiply, reduceSum, and Add\n",
    "n3 = h.make_node('Mul', inputs=['zx', 'c3'], outputs=['mulx'], name=\"multiplyBeta\")\n",
    "n4 = h.make_node('ReduceSum', inputs=['mulx'], outputs=['sumx'], name=\"reduceSum\", keepdims=0)\n",
    "n5 = h.make_node('Add', inputs=['sumx', 'c4'], outputs=['yhatlog'], name='addIntercept')\n",
    "\n",
    "# The graph\n",
    "g2 = h.make_graph([c3, c4, n3, n4, n5], 'linear_regression',\n",
    "       [h.make_tensor_value_info('zx', tp.FLOAT, [3])],\n",
    "       [h.make_tensor_value_info('yhatlog', tp.FLOAT, [1])])\n",
    "\n",
    "# The model and check:\n",
    "m2 = h.make_model(g2, producer_name='scailable-demo')\n",
    "checker.check_model(m2)\n",
    "\n",
    "# Save the model\n",
    "save(m2, 'linear-regression.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check:\n",
      "The log predicted price from ONNX is: [array([12.953111], dtype=float32)]\n",
      " - Compare to analysis in block 0: [12.953111]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "sess = rt.InferenceSession(\"linear-regression.onnx\")  # Start the inference session and open the model\n",
    "xin = standardized_input_example.astype(np.float32)  # Use the input_example from block 0 as input\n",
    "yhatlog = sess.run([\"yhatlog\"], {\"zx\": xin})  # Compute the standardized output\n",
    "\n",
    "print(\"Check:\")\n",
    "print(\"The log predicted price from ONNX is: {}\".format(yhatlog))\n",
    "print(\" - Compare to analysis in block 0: {}\".format(predicted_log_price_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 3: Constructing the post-processing pipeline\n",
    "Going from the log predicted price of the house to the actual verdict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (note using the constraints object created in block 0 above)\n",
    "c5 = h.make_node('Constant', inputs=[], outputs=['c5'], name=\"c5-node\", \n",
    "        value=h.make_tensor(name=\"c5v\", data_type=tp.FLOAT, \n",
    "        dims=constraints['maxprice'].shape, \n",
    "        vals=constraints['maxprice'].flatten()))\n",
    "c6 = h.make_node('Constant', inputs=[], outputs=['c6'], name=\"c6-node\", \n",
    "        value=h.make_tensor(name=\"c6v\", data_type=tp.FLOAT, \n",
    "        dims=constraints['minyard'].shape, \n",
    "        vals=constraints['minyard'].flatten()))\n",
    "\n",
    "# Auxilary constants for the slice operator:\n",
    "caux1 = h.make_node('Constant', inputs=[], outputs=['caux1'], name=\"caux1-node\",\n",
    "        value=h.make_tensor(name='caux1v', data_type=tp.INT32,\n",
    "        dims=np.array([0]).shape, vals=np.array([0]).flatten()))\n",
    "caux2 = h.make_node('Constant', inputs=[], outputs=['caux2'], name=\"caux2-node\",\n",
    "        value=h.make_tensor(name='caux2v', data_type=tp.INT32,\n",
    "        dims=np.array([1]).shape, vals=np.array([1]).flatten()))\n",
    "caux3 = h.make_node('Constant', inputs=[], outputs=['caux3'], name=\"caux3-node\",\n",
    "        value=h.make_tensor(name='caux3v', data_type=tp.INT32,\n",
    "        dims=np.array([0]).shape, vals=np.array([0]).flatten()))\n",
    "caux4 = h.make_node('Constant', inputs=[], outputs=['caux4'], name=\"caux4-node\",\n",
    "        value=h.make_tensor(name='caux4v', data_type=tp.INT32,\n",
    "        dims=np.array([1]).shape, vals=np.array([1]).flatten()))\n",
    "            \n",
    "# Nodes:\n",
    "n6 = h.make_node('Exp', inputs=['yhatlog'], outputs=['yhat'], name='exponent')\n",
    "n7 = h.make_node('Less', inputs=['yhat', 'c5'], outputs=['price_ok'], name='priceLess')\n",
    "\n",
    "n8 = h.make_node('Slice', inputs=['x', 'caux1', 'caux2', 'caux3', 'caux4'], outputs=['yard'],)\n",
    "n9 = h.make_node('Less', inputs=['c6', 'yard'], outputs=['yard_ok'], name=\"yardMore\") # note reversal\n",
    "\n",
    "n10 = h.make_node('And', inputs=['price_ok', 'yard_ok'], outputs=['result'], name='andBools')\n",
    "\n",
    "# The graph\n",
    "g3 = h.make_graph([c5, c6, caux1, caux2, caux3, caux4, n6, n7, n8, n9, n10], 'postprocessing',\n",
    "       [h.make_tensor_value_info('x', tp.FLOAT, [3]), h.make_tensor_value_info('yhatlog', tp.FLOAT, [1])],\n",
    "       [h.make_tensor_value_info('result', tp.BOOL, [1])])\n",
    "\n",
    "# The model and check:\n",
    "m3 = h.make_model(g3, producer_name='scailable-demo')\n",
    "checker.check_model(m3)\n",
    "\n",
    "# Save the model\n",
    "save(m3, 'post-processing.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check:\n",
      "Predicted price [422147.75] and yardsize 213.0 are appealing [array([False])].\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "sess = rt.InferenceSession(\"post-processing.onnx\")  # Start the inference session and open the model\n",
    "x = input_example.astype(np.float32)  # Use the input_example from block 0 as input\n",
    "\n",
    "yhatlog = np.array(yhatlog).flatten()\n",
    "result = sess.run([\"result\"], {\"x\": x, \"yhatlog\" : yhatlog})  # Compute the standardized output\n",
    "\n",
    "print(\"Check:\")\n",
    "print(\"Predicted price {} and yardsize {} are appealing {}.\".format(np.exp(yhatlog), input_example[0], result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 4: Creating a single graph for all operations\n",
    "While we could exectue each of the processing blocks defined above in turn, we can also create a single model containing the full inference pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_full = h.make_graph([c1, n1, c2, n2, c3, c4, n3, n4, n5, c5, c6, caux1, caux2, caux3, caux4, n6, n7, n8, n9, n10], \n",
    "        'fullpipeline',\n",
    "        [h.make_tensor_value_info('x', tp.FLOAT, [3])],\n",
    "        [h.make_tensor_value_info('result', tp.BOOL, [1])])\n",
    "\n",
    "m_full = h.make_model(g_full, producer_name='scailable-demo')\n",
    "checker.check_model(m_full)\n",
    "\n",
    "# Save the model\n",
    "save(m_full, 'full-pipeline.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check:\n",
      "Example [213. 167.   9.] is appealing: [array([False])].\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "sess = rt.InferenceSession(\"full-pipeline.onnx\")  # Start the inference session and open the model\n",
    "xin = input_example.astype(np.float32)  # Use the input_example from block 0 as input\n",
    "\n",
    "yhatlog = np.array(yhatlog).flatten()\n",
    "result = sess.run([\"result\"], {\"x\": xin})  # Compute the standardized output\n",
    "\n",
    "print(\"Check:\")\n",
    "print(\"Example {} is appealing: {}.\".format(xin, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
